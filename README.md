## Prompt-Engineering-using-OpenAI-API

## Problem Statement  

This project explores **prompt engineering techniques** for working with large language models (LLMs), specifically OpenAIâ€™s **GPT-3.5-turbo**.  
Prompt engineering is the process of designing input text (prompts) to guide LLMs in generating desired outputs.  

The project is structured into three main parts:  

### 1. **Set-up**  
- Installing dependencies and setting up OpenAI API for text generation.  
- Loading required libraries and defining helper functions.  

### 2. **Prompt Development & Experimentation**  
- **Zero-shot prompting:** Providing only instructions to the model without examples to generate a response.  
- **Few-shot prompting:** Supplying a few example responses to help the model understand the task.  
- **Chain-of-thought prompting:** Encouraging step-by-step reasoning to improve response accuracy.  

### 3. **Emotional Text Rewriting Task**  
- The goal is to rewrite a **GoFundMe campaign story** with different emotional tones.  
- By adjusting prompts, we evaluate how different techniques impact the generated text.  

### **Key Takeaways**  
- **Prompt engineering** is crucial for fine-tuning model outputs.  
- Different prompting techniques influence the clarity, tone, and accuracy of responses.  
- Experimentation is necessary to find the most effective prompt structure.  

### **Tools & Technologies Used**  
- **Python** for scripting and API interactions.  
- **OpenAI GPT-3.5-turbo** for text generation.  
- **Google Coproject** as the development environment.  

This project provides hands-on experience in **optimizing AI-generated text** through strategic prompt engineering.
